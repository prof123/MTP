
* Page Sharing
Survey of everything. Some history?
** Scanning vs Disk based sharing
2 competing approaches.
   (2)
* KSM
Diagram of operations, history, and some implementation details
Focus on generic nature
** Exp 1: KSM effectiveness
Small experiment which shows that KSM shares large % of same pages. Done earlier in fingerprinting project.
Expected result : > 90% sharing of KSM, so good enough.
Reason : establish some ground truths: KSM _works_ .
Setup : Random workload (doesnt matter) and take fingerprint and see KSM shar% . Run with 1,2,3 VMs.
   (1)
* Analysis of shared pages

** Exp 2: Pages shared by flag type -later
Run some benchmarks (static VMs just booted up ; Kernbench ; HTTP-perf) and see what kinds of pages are shared by flag type.
Reason: establish some ground truths : sharing is _feasible_ . Also answer : what _kinds_ of pages are shared?
Setup: (1,2,3,5) VMs with different OS running same benchmarks. (diff VMs ; same kernel ; same /var/www) 

** Exp 2.1 : KSM with no pagecache pages -later
Run KSM but skip all guest pagecache pages.

** Exp 2.2: Ftrace Overhead for KSM -notdoing
Since we are recording all KSM events (just for few experiments only) whats the overhead of that?
1GB/minute data collected.

** Exp 3: Page sharing over time -ok done
Run some benchmarks and record pages shared over the duration of benchmark. Also record *KSM overhead*.
Reason: Show that KSM overhead is significant enough, thus implying the need for some optimizations.
Setup: (2) VMs running benchmarks. KSM being profiled using perf.

(1)
* Lookahead optimization
  
** Exp 4: Lookahead success - desktop,install,kcompile. DONE
Run benchmarks on VMs (1,2,3) to on and record lookahead successes. Also record *KSM overhead*
*Compare vanilla KSM overhead with lookahead-optimization*

** Exp 5: Substrings in shared-map. - simple todo
Record consecutive pages being shared in some benchmarks.
Reason : justify why lookahead works.
Setup: tracedump analysis simple python script 

(3)
* Problem of double-caching
** Exp 6: Memory savings with exclusive caches - done for binnie iozone kcompile desktop
How many pages are there in both places?
Setup : Benchmarks on VMs.

** Exp 7: Overhead of ksm-exclusive-cache - done
Run benchmarks on VMs to record KSM overhead (with ex cache)
Reason : scanning vast host page cache could be significant overhead.Also savings might help.

Some caching theory references.
(1)
* Qualitative survey of dynamic memory management for VMs.
** Exp 8: Memory mountains - done? iozone bonnie?
Look at this problem like L1/2 cache , and build mem-mountains in these cases:
(normal ; no guest cache ; no host cache ; swap as ramdisk )
Setup : could use IOZone or randal bryant's simple program.
Reason : Demonstrate the latencies/throughput of various caches. 
*This depends on lots of factors like IO schedulers, FS, virtual disk layout etc. Do for any one, for now.*


what i have


* TODO MASTER TODO
SLIDES
* pte munging table

| Guest Physical Page | Host Physical Page |
|---------------------+--------------------|
| A                   | X                  |


| Guest Physical Page | Host Physical Page |
|---------------------+--------------------|
| B                   | Y                  |



| Guest Physical Page | Host Physical Page |
|---------------------+--------------------|
| A                   | K                  |


| Guest Physical Page | Host Physical Page |
|---------------------+--------------------|
| B                   | K                  |



diagram of qemu IO
* table of sharing for 3 workloads

| Workload (2VMs) | Shared Pages | Freed Memory |
|-----------------+--------------+--------------|
| Boot up         | 8,000        |              |
| Kernel Compile  | 26,000       |              |
| Desktop VM use  | 31,000       |              |


* table for lookahead success - 3 loads


| Workload (2VMs) | Avg. Shared Pages - Vanilla | Avg. Shared Pages - lookahead | CPU-look | CPU-Vanilla |
|-----------------+-----------------------------+-------------------------------+----------+-------------|
| Boot up         | 8,000                       | 11,000                        |       12 |          12 |
| Kernel Compile  | 26,000                      | 30,000                        |       22 |          19 |
| Desktop VM use  | 31,000                      | 62,000                        |     16.8 |        14.6 |




* graph for duplicate cache problem - just show yes > y output already. 
* table for excache benefits. BONNIE. 


| Workload  (2VMs)     | Avg. Shared Pages | Total Pages dropped | Avg Cache saved | CPU-ksm | CPU-exc |
|----------------------+-------------------+---------------------+-----------------+---------+---------|
| Kernel Compile(2 GB) | 75,000            |                     | 512M - 260M     |      14 |    16   |
| Desktop VM use       | 62,000            | 162,000             | 400M- 219M      |    18.8 |    14.6 |

BONNIE

| Test         | Plain      | With Excl Cache |
|--------------+------------+-----------------|
| Write(char)  | 24,000 K/s | 32,000 K/s      |
| Read(char)   | 27,000 K/s | 27,500 K/s      |
| Read(block)  | 53,750 K/s | 47,700 K/s      |
| Write(block) | 22,500 K/s | 23,800 K/s      |





PAPER
cache=none mystery -friday
kcompile 2,4 data -friday
Zipf -friday
freq of scanning -friday

* bonnie with diff cache policies (2,4 VMs) [last]
* iozone with various cache policies.[done]
* kcompile 4 with and without ksm. [TODO] 


| Benchmark                    | Pages Shared |
|------------------------------+--------------|
| 2 Desktop VMs(Deb and Mint)  |              |
| 2 Server Vms booted up       |              |
| 2 VMs running kernel compile |              |
|                              |              |

| Benchmark | Duplicate Cache Pages |   |
|-----------+-----------------------+---|
|           |                       |   |
|           |                       |   |

|   |   |   |
|---+---+---|
|   |   |   |
|   |   |   |
